"""
Research Trend Analyzer Service
- í‚¤ì›Œë“œ ê¸°ë°˜ ì—°êµ¬ íŠ¸ë Œë“œ ë¶„ì„
- ì—°ë„ë³„ ì¶œíŒ ë™í–¥
- í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
- ê¸‰ë¶€ìƒ ì£¼ì œ ì‹ë³„
- AI ê¸°ë°˜ ì—°êµ¬ ë‚´ìš© ìš”ì•½
"""

import asyncio
import logging
import re
from collections import Counter, defaultdict
from datetime import datetime
from typing import Any, Optional

from pydantic import BaseModel

logger = logging.getLogger(__name__)


class TrendData(BaseModel):
    """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ ë°ì´í„° ëª¨ë¸"""
    keyword: str
    total_papers: int
    year_trend: dict[str, Any] | None = None
    key_terms: dict[str, Any] | None = None
    emerging_topics: list[dict[str, Any]] | None = None
    content_summary: dict[str, Any] | None = None
    search_summary: dict[str, Any] | None = None


class TrendAnalyzer:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ì—°êµ¬ íŠ¸ë Œë“œ ë¶„ì„ê¸°"""

    # ì˜ì–´ ë¶ˆìš©ì–´
    STOPWORDS = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',
        'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
        'could', 'should', 'may', 'might', 'can', 'this', 'that', 'these',
        'those', 'it', 'its', 'they', 'them', 'their', 'we', 'our', 'you',
        'your', 'i', 'me', 'my', 'he', 'she', 'his', 'her', 'which', 'who',
        'whom', 'what', 'when', 'where', 'why', 'how', 'all', 'each', 'every',
        'both', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor',
        'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 'just',
        'also', 'now', 'here', 'there', 'then', 'once', 'if', 'because',
        'while', 'although', 'though', 'after', 'before', 'since', 'until',
        'about', 'into', 'through', 'during', 'above', 'below', 'between',
        'under', 'again', 'further', 'then', 'once', 'study', 'studies',
        'results', 'conclusion', 'methods', 'background', 'objective',
        'aim', 'purpose', 'introduction', 'discussion', 'however', 'thus',
        'therefore', 'moreover', 'furthermore', 'additionally', 'including',
        'included', 'using', 'used', 'based', 'associated', 'related',
        'compared', 'among', 'within', 'without', 'between', 'across'
    }

    # ì—°êµ¬ ì£¼ì œ í‚¤ì›Œë“œ ë§¤í•‘
    THEME_KEYWORDS = {
        'diagnosis': ['diagnosis', 'diagnostic', 'detection', 'screening', 'biomarker'],
        'treatment': ['treatment', 'therapy', 'therapeutic', 'drug', 'intervention', 'medication'],
        'mechanism': ['mechanism', 'pathway', 'molecular', 'cellular', 'signaling'],
        'prevention': ['prevention', 'preventive', 'risk factor', 'protective'],
        'clinical': ['clinical', 'trial', 'patient', 'outcome', 'efficacy'],
        'review': ['review', 'overview', 'comprehensive', 'systematic', 'meta-analysis'],
        'epidemiology': ['epidemiology', 'prevalence', 'incidence', 'population'],
        'genetics': ['genetic', 'gene', 'mutation', 'hereditary', 'genomic'],
    }

    THEME_NAMES = {
        'diagnosis': 'ì§„ë‹¨/ê²€ì¶œ',
        'treatment': 'ì¹˜ë£Œ/ì•½ë¬¼',
        'mechanism': 'ë©”ì»¤ë‹ˆì¦˜/ê²½ë¡œ',
        'prevention': 'ì˜ˆë°©/ìœ„í—˜ìš”ì¸',
        'clinical': 'ì„ìƒì—°êµ¬',
        'review': 'ì¢…í•©ë¦¬ë·°',
        'epidemiology': 'ì—­í•™ì—°êµ¬',
        'genetics': 'ìœ ì „í•™ì—°êµ¬'
    }

    def __init__(self, openai_api_key: str | None = None):
        """
        Args:
            openai_api_key: OpenAI API í‚¤ (AI ìš”ì•½ ê¸°ëŠ¥ìš©)
        """
        self.openai_api_key = openai_api_key
        self.papers: list[dict[str, Any]] = []
        self.trend_data: dict[str, Any] = {}

    def set_papers(self, papers: list[dict[str, Any]]) -> None:
        """ë¶„ì„í•  ë…¼ë¬¸ ë°ì´í„° ì„¤ì •"""
        self.papers = papers
        self.trend_data = {}

    def analyze_publication_trend(self) -> dict[str, Any]:
        """ì—°ë„ë³„ ì¶œíŒ íŠ¸ë Œë“œ ë¶„ì„"""
        if not self.papers:
            return {}

        years: list[int] = []
        for paper in self.papers:
            pub_date = paper.get('publication_date') or paper.get('published', '')
            if pub_date:
                try:
                    if isinstance(pub_date, datetime):
                        year = pub_date.year
                    else:
                        year = int(str(pub_date)[:4])
                    if 2000 <= year <= 2030:
                        years.append(year)
                except (ValueError, TypeError):
                    pass

        year_counts = Counter(years)
        sorted_years = sorted(year_counts.items())

        self.trend_data['year_trend'] = {
            'years': [y[0] for y in sorted_years],
            'counts': [y[1] for y in sorted_years],
            'total': len(years)
        }

        return self.trend_data['year_trend']

    def extract_key_terms(self, top_n: int = 20) -> dict[str, Any]:
        """ë…¼ë¬¸ ì´ˆë¡ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not self.papers:
            return {}

        all_words: list[str] = []
        for paper in self.papers:
            abstract = paper.get('abstract') or ''
            if abstract:
                words = re.findall(r'\b[a-zA-Z]{3,}\b', abstract.lower())
                words = [w for w in words if w not in self.STOPWORDS]
                all_words.extend(words)

        word_counts = Counter(all_words)
        top_terms = word_counts.most_common(top_n)

        self.trend_data['key_terms'] = {
            'terms': [t[0] for t in top_terms],
            'counts': [t[1] for t in top_terms]
        }

        return self.trend_data['key_terms']

    def identify_emerging_topics(self) -> list[dict[str, Any]]:
        """ìµœê·¼ ê¸‰ë¶€ìƒí•˜ëŠ” ì£¼ì œ ì‹ë³„"""
        if not self.papers or len(self.papers) < 5:
            return []

        current_year = datetime.now().year
        recent_papers: list[dict] = []
        older_papers: list[dict] = []

        for paper in self.papers:
            pub_date = paper.get('publication_date') or paper.get('published', '')
            try:
                if isinstance(pub_date, datetime):
                    year = pub_date.year
                else:
                    year = int(str(pub_date)[:4])

                if year >= current_year - 1:
                    recent_papers.append(paper)
                else:
                    older_papers.append(paper)
            except (ValueError, TypeError):
                pass

        if not recent_papers or not older_papers:
            return []

        def extract_terms(papers: list[dict]) -> Counter:
            words: list[str] = []
            for paper in papers:
                abstract = paper.get('abstract') or ''
                if abstract:
                    w = re.findall(r'\b[a-zA-Z]{4,}\b', abstract.lower())
                    words.extend([x for x in w if x not in self.STOPWORDS])
            return Counter(words)

        recent_terms = extract_terms(recent_papers)
        older_terms = extract_terms(older_papers)

        emerging: list[dict[str, Any]] = []
        for term, recent_count in recent_terms.most_common(50):
            older_count = older_terms.get(term, 0)
            if older_count == 0:
                growth = 999.0
            else:
                growth = (recent_count / len(recent_papers)) / (older_count / len(older_papers))

            if growth > 1.5 and recent_count >= 3:
                emerging.append({
                    'term': term,
                    'recent_count': recent_count,
                    'older_count': older_count,
                    'growth_rate': growth if growth != 999 else 999.0
                })

        emerging.sort(key=lambda x: x['growth_rate'], reverse=True)
        self.trend_data['emerging_topics'] = emerging[:10]

        return self.trend_data['emerging_topics']

    def summarize_research_content(self, keyword: str) -> dict[str, Any]:
        """ì—°êµ¬ ë‚´ìš© ìš”ì•½ ìƒì„±"""
        if not self.papers:
            return {}

        # ì£¼ìš” ì—°êµ¬ ì£¼ì œ ì¶”ì¶œ
        research_themes: dict[str, int] = {k: 0 for k in self.THEME_KEYWORDS}

        for paper in self.papers:
            title = paper.get('title') or ''
            abstract = paper.get('abstract') or ''
            text = (title + ' ' + abstract).lower()
            for theme, keywords in self.THEME_KEYWORDS.items():
                for kw in keywords:
                    if kw in text:
                        research_themes[theme] += 1
                        break

        sorted_themes = sorted(research_themes.items(), key=lambda x: x[1], reverse=True)
        top_themes = [(t, c) for t, c in sorted_themes if c > 0][:5]

        representative_papers = self.papers[:10]

        summary_text = self._generate_basic_content_summary(keyword, top_themes)

        self.trend_data['content_summary'] = {
            'themes': top_themes,
            'representative_papers': representative_papers,
            'summary_text': summary_text
        }

        return self.trend_data['content_summary']

    def _generate_basic_content_summary(
        self,
        keyword: str,
        themes: list[tuple[str, int]]
    ) -> str:
        """ê¸°ë³¸ ì—°êµ¬ ë‚´ìš© ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±"""
        summary_parts = []

        if themes:
            main_themes = [self.THEME_NAMES.get(t[0], t[0]) for t in themes[:3]]
            summary_parts.append(
                f"'{keyword}' ì—°êµ¬ëŠ” ì£¼ë¡œ {', '.join(main_themes)} ë¶„ì•¼ì— ì§‘ì¤‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤."
            )

        if self.papers:
            recent_titles = [(p.get('title') or '')[:80] for p in self.papers[:3]]
            summary_parts.append("\nìµœê·¼ ì£¼ìš” ì—°êµ¬:")
            for i, title in enumerate(recent_titles, 1):
                summary_parts.append(f"  {i}. {title}...")

        return "\n".join(summary_parts)

    async def generate_ai_summary(self, keyword: str) -> str | None:
        """OpenAIë¥¼ ì‚¬ìš©í•œ AI ìš”ì•½ ìƒì„±"""
        if not self.openai_api_key or not self.papers:
            return None

        try:
            from openai import AsyncOpenAI
            client = AsyncOpenAI(api_key=self.openai_api_key)

            abstracts = []
            for paper in self.papers[:10]:
                title = paper.get('title') or ''
                abstract = (paper.get('abstract') or '')[:600]
                pub_date = paper.get('publication_date') or paper.get('published', '')
                year = ''
                if pub_date:
                    if isinstance(pub_date, datetime):
                        year = str(pub_date.year)
                    else:
                        year = str(pub_date)[:4]
                authors = paper.get('authors', [])
                author_str = ', '.join(authors[:3]) if isinstance(authors, list) else str(authors)[:50]
                abstracts.append(f"[{year}] {title}\nì €ì: {author_str}\nì´ˆë¡: {abstract}")

            combined_text = "\n\n---\n\n".join(abstracts)

            year_stats = ""
            if 'year_trend' in self.trend_data:
                years = self.trend_data['year_trend']['years'][-5:]
                counts = self.trend_data['year_trend']['counts'][-5:]
                year_stats = "\n\nì—°ë„ë³„ ë…¼ë¬¸ ìˆ˜: " + ", ".join(
                    [f"{y}ë…„: {c}í¸" for y, c in zip(years, counts)]
                )

            prompt = f"""ë‹¹ì‹ ì€ ì˜í•™/ê³¼í•™ ì—°êµ¬ ë™í–¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒì€ '{keyword}'ì— ê´€í•œ ìµœê·¼ ì—°êµ¬ ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.

ì´ ë¶„ì„ ë…¼ë¬¸ ìˆ˜: {len(self.papers)}í¸{year_stats}

=== ë…¼ë¬¸ ëª©ë¡ ===
{combined_text}

ìœ„ ì—°êµ¬ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ '{keyword}' ë¶„ì•¼ì˜ ì—°êµ¬ ë™í–¥ì„ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”:

ğŸ“Œ **ì—°êµ¬ ê°œìš”**: (ì´ ë¶„ì•¼ê°€ ë¬´ì—‡ì„ ë‹¤ë£¨ëŠ”ì§€ 1-2ë¬¸ì¥)

ğŸ”¬ **ì£¼ìš” ì—°êµ¬ ë°©í–¥**:
- (ìµœê·¼ ì—°êµ¬ë“¤ì´ ì§‘ì¤‘í•˜ëŠ” í•µì‹¬ ì£¼ì œ 2-3ê°€ì§€)

ğŸ’¡ **í•µì‹¬ ë°œê²¬/ê²°ê³¼**:
- (ì£¼ìš” ì—°êµ¬ ê²°ê³¼ë‚˜ ë°œê²¬ 2-3ê°€ì§€)

ğŸ”® **í–¥í›„ ì „ë§**:
- (ì—°êµ¬ íŠ¸ë Œë“œ ë° í–¥í›„ ë°©í–¥ 1-2ë¬¸ì¥)

í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            response = await client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì˜í•™/ê³¼í•™ ì—°êµ¬ ë™í–¥ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
                    },
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )

            return response.choices[0].message.content.strip()

        except Exception as e:
            logger.warning(f"AI summary generation failed: {e}")
            return None

    async def analyze(self, keyword: str) -> TrendData:
        """ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤í–‰"""
        if not self.papers:
            return TrendData(keyword=keyword, total_papers=0)

        # ë¶„ì„ ìˆ˜í–‰
        self.analyze_publication_trend()
        self.extract_key_terms()
        self.identify_emerging_topics()
        self.summarize_research_content(keyword)

        # AI ìš”ì•½ ìƒì„± (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)
        if self.openai_api_key:
            ai_summary = await self.generate_ai_summary(keyword)
            if ai_summary and 'content_summary' in self.trend_data:
                self.trend_data['content_summary']['ai_summary'] = ai_summary

        return TrendData(
            keyword=keyword,
            total_papers=len(self.papers),
            year_trend=self.trend_data.get('year_trend'),
            key_terms=self.trend_data.get('key_terms'),
            emerging_topics=self.trend_data.get('emerging_topics'),
            content_summary=self.trend_data.get('content_summary'),
            search_summary=self.trend_data.get('search_summary')
        )

    def generate_report(self, keyword: str) -> str:
        """íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append(f"\n{'=' * 60}")
        report.append(f"ğŸ“ˆ '{keyword}' ì—°êµ¬ íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("=" * 60)
        report.append(f"\nğŸ“Š ë¶„ì„ ëŒ€ìƒ: {len(self.papers)}ê°œ ë…¼ë¬¸\n")

        # ì—°ë„ë³„ íŠ¸ë Œë“œ
        if 'year_trend' in self.trend_data:
            years = self.trend_data['year_trend']['years']
            counts = self.trend_data['year_trend']['counts']
            if years:
                report.append("ğŸ“… ì—°ë„ë³„ ì¶œíŒ ë™í–¥:")
                for year, count in list(zip(years, counts))[-5:]:
                    bar = "â–ˆ" * (count * 2)
                    report.append(f"   {year}: {bar} ({count})")

                if len(counts) >= 2:
                    recent_avg = sum(counts[-2:]) / 2
                    older_avg = sum(counts[:-2]) / max(len(counts) - 2, 1) if len(counts) > 2 else counts[0]
                    if recent_avg > older_avg * 1.2:
                        report.append("\n   ğŸ“ˆ íŠ¸ë Œë“œ: ìƒìŠ¹ì„¸ (ìµœê·¼ ì—°êµ¬ ì¦ê°€)")
                    elif recent_avg < older_avg * 0.8:
                        report.append("\n   ğŸ“‰ íŠ¸ë Œë“œ: í•˜ë½ì„¸ (ì—°êµ¬ ê´€ì‹¬ ê°ì†Œ)")
                    else:
                        report.append("\n   â¡ï¸ íŠ¸ë Œë“œ: ì•ˆì •ì  (ê¾¸ì¤€í•œ ì—°êµ¬)")

        # í•µì‹¬ í‚¤ì›Œë“œ
        if 'key_terms' in self.trend_data:
            report.append("\nğŸ”‘ í•µì‹¬ í‚¤ì›Œë“œ (Top 10):")
            terms = self.trend_data['key_terms']['terms'][:10]
            counts = self.trend_data['key_terms']['counts'][:10]
            for i, (term, count) in enumerate(zip(terms, counts), 1):
                report.append(f"   {i:2d}. {term} ({count}íšŒ)")

        # ê¸‰ë¶€ìƒ ì£¼ì œ
        if 'emerging_topics' in self.trend_data and self.trend_data['emerging_topics']:
            report.append("\nğŸš€ ê¸‰ë¶€ìƒ ì£¼ì œ (ìµœê·¼ vs ê³¼ê±°):")
            for i, e in enumerate(self.trend_data['emerging_topics'][:5], 1):
                growth = e['growth_rate']
                growth_str = "NEW!" if growth >= 999 else f"{growth:.1f}x"
                report.append(f"   {i}. {e['term']} - {growth_str} ì„±ì¥")

        # ì—°êµ¬ ë‚´ìš© ìš”ì•½
        if 'content_summary' in self.trend_data:
            summary_data = self.trend_data['content_summary']
            report.append(f"\n{'-' * 60}")
            report.append("ğŸ“‹ ì—°êµ¬ ë‚´ìš© ìš”ì•½")
            report.append("-" * 60)

            if 'themes' in summary_data and summary_data['themes']:
                report.append("\nğŸ”¬ ì£¼ìš” ì—°êµ¬ ë¶„ì•¼:")
                for theme, count in summary_data['themes'][:5]:
                    theme_name = self.THEME_NAMES.get(theme, theme)
                    bar = "â–“" * min(count, 20)
                    report.append(f"   â€¢ {theme_name}: {bar} ({count}í¸)")

            if 'ai_summary' in summary_data:
                report.append("\nğŸ“ AI ì—°êµ¬ ë™í–¥ ìš”ì•½:")
                for line in summary_data['ai_summary'].split('\n'):
                    if line.strip():
                        report.append(f"   {line}")

        report.append(f"\n{'=' * 60}")

        return "\n".join(report)


# Singleton instance factory
def create_trend_analyzer(openai_api_key: str | None = None) -> TrendAnalyzer:
    """TrendAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
    return TrendAnalyzer(openai_api_key=openai_api_key)
